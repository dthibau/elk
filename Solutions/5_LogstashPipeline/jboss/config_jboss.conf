input {
    
file {
    path => "/home/dthibau/Formations/ElasticStack/MyWork/TPS/5_LogstashPipeline/jboss/**/*.log*"
    start_position => beginning
    codec => multiline {
    	pattern => "^\s|^Caused by"
      	what => "previous"
    }
  }



}


filter {
	if [path] =~ "server" { 
		mutate { replace => { type => "appli" } }
		# Test date in file name
		if [path] =~ "20" {
			grok {
				match => {
					"path" => "(?<logdate>[0-9A-F]{4}-[0-9A-F]{2}-[0-9A-F]{2})"
				}
			}	
		} else {
			mutate {
				# this will only work on logs created the same day as read
				add_field => {"logdate" => "%{+YYYY-MM-dd}"}
			}
		}

		# Separate fields
		grok { 
			match => { 
			 	"message" => "%{TIME:time}%{SPACE}%{LOGLEVEL:level}%{SPACE}\[%{DATA:className}\]%{SPACE}%{GREEDYDATA:message}"
		 	
			} 
		}
		# If time des not exist set it 
		if [time] !~ "[0-9]" {
			mutate {
					# merge with existing time field
					add_field => {"time" => "%{+HH:mm:ss,SSS}"}
				}
		}

		# set timestamp
		date { match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ] }
		mutate {
			add_field => {"full_date" => "%{logdate}_%{time}"}
		}
		date {
			match => ["full_date", "YYYY-MM-dd_HH:mm:ss,SSS"]
		}
		date {
				match => ["time", "HH:mm:ss,SSS"]
				target => "time"
			}
		if [level] == "INFO" {
    			drop { }
  		}
	} else {
		mutate { replace => { type => "other" } }		
	}
}

output {
   
elasticsearch {
#        hosts => [ "localhost:9200" ]
		hosts => [ "192.168.13.11:9200", "192.168.13.6:9200" ]
	index => "jboss-david-2016"
    }

stdout { codec => rubydebug }

}
